1. 矩阵的秩，满秩代表什么？不满秩呢？
   - 矩阵的秩，满秩代表矩阵的每一行都有一个主元，表明线性方程组一定有解，且所生的向量也为 n 维。
   - 不满秩与上述相反，说明至少有一行不存在主元，若存在一行全 0 则说明所形成的线性方程组有无穷多个解，若最后一列为非 0 且是非线性方程组无解。
   - 矩阵 A 的不等于零的子式的最高阶数称作矩阵 A 的秩。
   - 一个秩为 n 的矩阵满秩意味着存在一个 n 阶子式不为 0。
   - 不满秩的话，假设其秩为 r，意味着所有大于 r 阶的子式都为 0。

2. 什么是线性相关？什么是线性无关？
   - 线性相关：一组数据中有一个或者多个量可以被其余量表示。
   - 线性无关：于线性相关相反，也叫线性独立。
   - 对于线性空间中的 n 个向量，假如存在 n 个常数使得这 n 个常数与 n 个向量对应乘积加和等于 0，则称这 n 个向量线性相关，如果不存在这样的 n 个常数，称之为线性无关。

参考资料：《线性代数 成立波》65 页

3. 什么是向量空间？线性空间？
   - 凡是具有加法结构和数乘结构的集合都可以叫做线性空间。向量空间指一个有线性运
      算规的集合，集合的元素可以称为向量，规则是线性运算（即加法和数乘一般性数学定理）。
   - 所有 n 维向量构成的集合称为 n 维向量空间。
   - 将 n 维向量空间抽象化，便引出线性空间的概念。定义集合 V 上的两种代数运算：加法
      和数乘。V 中任意两向量之和与 V 中的一个向量 gamma 对应；V 中任意向量和域 K 中的任一
      数 lambda 的数乘与 V 中的一个向量 eta 对应。

并且加法满足交换律、结合律、零元、逆元，数乘存在单位元、满足结合律，数乘关于

加法满足分配律。

那么这个集合 V 就称作线性空间，又叫向量空间。V 中的元素统称为“向量“。

参考资料：《线性代数与矩阵论 许以超》书不好找，直接放截图了
这里的“纯量积”其实就是数乘：常数乘向量（伸缩变换）
4. 什么是向量的基？
   - 在线性空间 V 中可以找到 n 个向量，这 n 个向量线性无关，并且线性空间 V 中的任意一
      向量都可以用这 n 个向量的线性组合来表示。这 n 个向量就被称为向量空间 V 的基。

参考资料：《线性代数与矩阵论 许以超》书不好找，直接放截图了

1. 交换行：将第 i 行与第 j 行互换。
2. 移动行：将第 i 行移动到第 j 行的位置。
3. 缩放行：将第 i 行的每个元素都乘以一个非零常数 c。

参考资料：《线性代数与矩阵论 许以超》书不好找，直接放截图了

1. **变量与随机变量的区别**
   - 变量是用来量化确定性的现象的函数，其取值是固定唯一的，并且取值范围是整个定义域。
   - 随机变量是用来量化随机现象的函数，其取值有多个，而且每个取值都有一定的概率。在试验之前，随机变量的取值是不能预知的，试验之后，随机变量的取值范围就是这次试验的样本空间。

2. **随机变量与概率分布的关系**
   - 随机变量的分布函数表述了随机变量的统计规律性，已知一个随机变量的分布函数就可以得知该随机变量落在某一区间的概率。
   - 在联合概率的基础上固定若干个随机变量的取值便得到边缘概率。

3. **常见的概率分布有哪些？应用场景及例子**
   - 离散分布：二项分布（n重伯努利检验，常用于检查产品合格率、色盲率调查等等）、两点分布（01分布）（比赛胜率估计）、泊松分布（单位时间内或单位空间中事件数量的频数分布。常用于一天内到达顾客数、铸件上的砂眼数、一天内电路受到电磁波干扰次数等等）、超几何分布（用于进行有限总体中进行不放回抽样）。
   - 连续分布：均匀分布（正态分布：主要应用于统计理论、误差理论等等）、指数分布（建模各次事件之间的时间分布情况。常用于随即服务系统、寿命估计、排队论等等）。

4. **大数定律和中心极限定理的意义与作用**
   - 切比雪夫大数定律：只要随机试验的次数 n 充分大，样本均值趋近于总体均值，指明了平均结果的渐趋稳定性。
   - 辛钦大数定理：说明了对于独立同分布且具有均值 u 的 n 个随机变量，当 n 很大的时候它们的算术平均值依概率收敛于 u。样本均值稳定于数学期望。
   - 伯努利大数定律表明只要随机试验的次数 n 充分大，那么事件 A 频率和概率的绝对偏差很小，说明在实际应用中，试验次数很大的时候可以用事件的频率来替代事件的概率。频率稳定于概率。

5. **独立同分布的中心极限定理：均值为 u，标准差为 sigma 的独立同分布的 n 个随机变量之和的标准化变量在 n 充分大的时候近似服从于标准正态分布。大量独立同分布的随机变量和的极限分布服从标准正态分布。

1. **正态分布的性质与独立同分布**：正态分布的和仍然是正态分布，这叫做正态分布的可加性。
2. **假设检验**：假设检验是一种统计推断方法，用于判断样本与样本、样本与总体的差异是由抽样误差引起还是本质差别造成的。基本思想是“小概率事件”原理，统计推断方法是带有某种概率性质的反证法。小概率思想是指小概率事件（此小概率也称：检验的显著性水平，一般取 0.05，0.01，0.1）在一次试验中基本上不会发生。反证法思想是先提出检验假设，再用适当的统计方法，利用小概率原理，确定假设是否成立。即为了检验一个假设 H0 是否正确，首先假定该假设 H0 正确，然后根据样本对假设 H0 做出接受或拒绝的决策。如果样本观察值导致了“小概率事件”发生，就应拒绝假设 H0，否则应接受假设 H0。
3. **独立同分布的正态分布随机变量的和仍然服从正态分布**：如果多个随机变量分别服从不同的正态分布，如果这些随机变量彼此独立，那么这些随机变量的和也服从正态分布。
4. **独立和不相关的区别**：独立一定不相关，而不相关不一定独立。例如线性不相关的随机变量可能是非线性相关。最常见的例子就是 Logistics 函数或者二次函数，自变量和因变量计算所得相关系数很低，但是是互相依赖的变量。
5. **概率密度函数**：概率密度函数能在一定程度上反应随机变量 X 在某点附近取值的概率大小，但概率密度函数不是概率，乘以区间长度微元后就表示概率的近似值，而概率密度函数在一段区间上积分就是随机变量 X 在这段区间上取值的概率。因此，如果存在实数轴上的一个非负可积函数使得对任意实数 x 都有“这个函数从负无穷到 x 的积分值就是随机变量 X 的分布函数 F(x)”，这个函数称为随机变量 X 的概率密度函数。
6. **泊松分布的例子**：泊松分布常用于描述单位时间内发生特定事件的次数，如电话呼叫、交通流量等。
7. **全概率公式和贝叶斯公式**：全概率公式表示达到某个目的，有多种方式（或者造成某种结果，有多种原因），问达到目的的概率是多少（造成这种结果的概率是多少）。贝叶斯公式则是在已知部分条件的情况下，求解另一部分条件下的概率。

1. **全概率公式**
   全概率公式是贝叶斯定理的基础，用于计算在给定某些事件发生的情况下，其他事件发生的概率。

2. **相关系数、协方差、相关系数或协方差为 0 的时候能否说明两个分布无关？**
   协方差是衡量两个随机变量之间线性关系强度的统计量，如果协方差为 0，则表示两个随机变量线性无关；但是，协方差为 0 并不代表两个随机变量完全无关，可能存在非线性相关关系。

3. **若干正态分布相加、相乘后得到的分布分别是什么？**
   相加：正态分布相加后仍为正态分布，均值和方差分别为原分布的均值和方差的和。
   相乘：正态分布相乘后服从的分布为：正态分布乘以常数。

4. **如何做才能得出 1/2？**
   利用不均匀硬币产生等概率：通过多次投掷硬币，使正面朝上的次数接近 1/2。

5. **为什么机器学习要用到概率？**
   机器学习是由数据驱动的方法，需要对数据进行建模和预测，而这些都需要概率作为基础。同时，机器学习模型的训练和预测过程的评价指标——模型误差，也是概率的形式。

6. **什么是极大似然估计？**
   极大似然估计是一种参数估计方法，通过最大化似然函数来估计模型参数。通俗理解来说，就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。

7. **参数估计方法？**
   参数估计方法包括最小二乘法、最大似然估计、贝叶斯估计等。

8. **如何评价求出的估计量的好坏？**
   评估估计量好坏的标准包括无偏性、有效性、一致性、稳定性等。无偏性是指估计量求出来的参数可能偏高可能偏低，但总体的平均值等于未知参数；有效性是指估计量能够较好地反映真实参数；一致性是指不同样本条件下，估计量的结果一致；稳定性是指估计量对异常值的影响较小。

1. **泰勒展开和傅立叶变换的概念及应用**
   - 泰勒展开：为了便于研究复杂的函数，用多项式来近似表达函数可以简单地进行计算，而泰勒多项式就是用多项式近似函数的一种方法，函数在某一点处展开为泰勒多项式就是泰勒展开。
   - 傅立叶变换：傅里叶变换和其逆变换是一对互逆的运算，是用于对函数进行变换的工具。傅里叶变换可以将时域的非周期连续信号，转换为频域的非周期连续信号。
   - 泰勒展开在计算机领域的应用：数值微积分的很多定理和结论都是由泰勒展开推导得出。
   - 傅立叶变换在信号处理上的应用：可以轻松地滤掉特定频率成分的波；在求解微分方程上，可以让微分和积分在频率中变为乘法和除法；在计算机科学中，作为 DFT 算法的理论基础。

2. **离散型随机变量和连续型随机变量**
   - 离散型随机变量：取值是有限个数的随机变量称为离散型随机变量。
   - 连续型随机变量：取值是无限多个实数的随机变量称为连续型随机变量。

3. **概率和统计的区别**
   - 概率：已知模型和参数，推数据。
   - 统计：已知数据，推模型和参数。

4. **概率和似然的区别**
   - 概率：描述随机现象出现的可能性。
   - 似然：描述观察到的数据符合某一假设的概率。

5. **函数是分布函数充要条件**
   - 充要条件：如果函数是分布函数，则函数是连续的，且在所有点上都连续。
   - 如果函数是连续的，则函数是分布函数，但不一定是正态分布函数。

6. **函数的可积性和连续性**
   - 可积性：函数在某一点处的极限存在且等于零，函数在该点处是可积的。
   - 连续性：函数在某一点处的极限存在且等于函数在该点处的值，函数在该点处是连续的。

7. **概率密度函数和累积分布函数**
   - 概率密度函数：描述随机变量取值的概率分布。
   - 积累分布函数：描述随机变量取值的累积概率分布。

8. **贝叶斯公式**
   - 先验概率：在得到“结果”的信息前重新修正的概率，如贝叶斯公式中的。
   - 后验概率：表示在事情已经发生的条件下，要求该事发生原因是有某个因素引起的可能性的大小。

9. **极大似然估计**
   - 定义：利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。
   - 特点：极大似然估计是一种基于数据的统计方法，不需要知道模型的具体形式，只需要知道模型的参数空间以及观测到的数据。

10. **参数估计方法**
    - 无偏性：即估计量求出来的参数可能偏高可能偏低，但总体的平均值等于未知参数θ，样本均值和方差分别为总体均值和方差的无偏估计量。
    - 有效性：所估计出的参数在所构造的估计量中的方差要尽量小，即在参数θ附近的分散程度要小。
    - 一致性：当样本容量无限增大时，估计量能在某种意义下充分接近于被估计的参数。
    - 区间估计：点估计有一定的精度，如果要反映出精度可以采用区间估计。即在某个区间内取到参数θ的概率（即>=置信度）。利用伯努利大数定律，一个区间以一定的概率包含参数θ，当试验次数无穷大时，频率接近于置信度。区间的长度意味着误差，与点估计互补，且与精
准性相互矛盾，精度越大，区间长度越小。

1. **傅里叶变换和傅里叶级数的区别**

    傅里叶级数是一个函数的近似表达，是将一个函数通过三角函数系进行表达的表达式。

    傅里叶级数仍然是一个函数。傅里叶级数拥有三角和复数两种表达形式。

    而傅里叶变换是“函数的函数”，是一个对函数进行变换，使其拥有不同的特性，从时域转换到频域的工具。傅里叶变换是从傅里叶级数的复数形式推导而来。

    参考百度百科词条：“傅里叶变换”

2. **函数零点和极值点怎么求？**

    函数的零点求法：

        - 首先是，解析解：令函数值等于 0，然后解方程得到零点。
        - 对于过于复杂无法求方程解的情况，使用数值方法：二分法、牛顿迭代法

    极值点：

        - 对函数求导，然后令导函数等于 0，按照上述方法求导函数的零点即可，对于所得零点
            - 若两端同号，所得的解是驻点而不是极值点，
            - 若两端异号，就是极值点。

3. **判断两个无穷集合的大小，单射满射和双射的概念？**

    判断无穷集合的大小要引入“势”的概念，在谈论这个问题之前，需要先说说双射的概
    现。有穷集合和无穷集合相比的差别。

        - 单射和满射。若 A 到 B 的函数满足“任一值域 B 中的一个值都存在定义域 A
            中唯一的值与之对应”，这个函数就是单射的，若函数满足值域为集合 B，就称函数时满射
                的。

        - 若函数既是单射的又是满射的，就称作函数是双射的，这意味着函数的定义域
            为集合 A，值域为集合 B，且是单调函数。例如直线方程 y=kx+b，是集合 R->R 的双射函数，
                例如函数 y=tanx 是(0，1)->R 的双射函数。

    无穷集合的大小通过集合的势来衡量，若是一个集合的势小于自然数集的势“阿列夫零”，

    它就是有穷集。假如两个集合之间能够建立一一映射，那就是等势的，例如整数集、偶数集、
    有理数集都和自然数集等势，也就是一样大小。而实数集和它任一子集都是等势的，且大于
    自然数集。且康托定理指出，一个集合的幂集都大于当前集合。

4. **欧氏距离及常见距离公式的缺点？**

    欧氏距离也就是 n 维空间中两点之间的线段长度。

    缺点在于，会受到数据尺度的影响而产生偏斜，需要对数据进行归一化后

使用。

    余弦相似距离缺点在于只考虑了数据的方向，而没考虑向量的大小，受到数据尺度的

影响较大。

    欧氏距离体现数值上的绝对差异，而余弦距离体现方向上的相对差异。

    曼哈顿距离就是街道距离，缺点在于不够直观，并且距离不是最短距离。
    参考资料：https://blog.csdn.net/Datawhale/article/details/113787498

5. **最大似然估计是什么？**

    最大似然估计是一种统计学中的概率估计方法，其基本思想是，根据已知的数据，计算出使这些数据出现的可能性最大的参数值。

    操作方法就是，固定样本的观察值，在参数的取值空间中挑选使得似然函数在该样本值

    下达到最大值的参数，作为参数的估计值。

    《概统 浙大第四版》152 页

6. **梯度方向导数与梯度下降？**

    导数的本质：当自变量的变化量趋于 0 时，函数值的变化量与自变量变化量比值的极限
    偏导数：偏导数，指的是多元函数中，函数 y 在某一点处沿某一坐标轴正方向的变化

率。偏导数其实是方向导数的一种特殊情况。

    方向导数：某一点在某一趋近方向上的导数值，各个坐标轴的偏导数组成的向量，和

方向向量的内积。

    梯度：是一个矢量，其方向上的方向导数最大，其大小正好是此最大方向导数( 函数沿

梯度方向有最大的变化率 )。就是各个偏导数组成的向量。

    《同济第七版高等数学下册》103 页
    梯度下降法：既然在变量空间的某一点处，函数沿梯度方向具有最大的变化率，那么在
    优化目标函数的时候，自然是沿着负梯度方向去减小函数值，以此达到我们的优化目标。从
    函数的任一点开始，沿着该店梯度反方向运动一段距离，再沿新位置的梯度反方向运行一段
    距离，如此迭代一直超着函数下坡最陡的方向运动，以此运动到函数的近似极小点。

    参考资料：https://zhuanlan.zhihu.com/p/22387613

1. 哈密顿图：哈密顿图是指图中的每一条边都经过顶点一次，且没有重复路径的图。
2. 欧拉图：欧拉图是指图中的每一条边都经过顶点两次，且没有重复路径的图。

求解方法：
1. 哈密顿图：可以使用深度优先搜索或者广度优先搜索来求解。深度优先搜索是从图的一个顶点开始，沿着一条路径一直走到图的终点，然后再返回起点，再沿着另一条路径一直走到图的终点，然后再返回起点，如此反复，直到所有的顶点都被访问过为止。广度优先搜索则是从图的一个顶点开始，按照层次的方式遍历图的所有顶点，先访问距离自己最近的顶点，然后访问距离自己更远的顶点，以此类推，直到所有的顶点都被访问过为止。
2. 欧拉图：可以使用回溯法来求解。回溯法是一种通过尝试所有可能的解决方案来解决问题的方法。具体来说，回溯法会从问题的起始状态开始，然后根据问题的要求，逐步向后推进，尝试各种可能的解决方案，直到找到满足要求的解决方案为止。
't

1. 欧拉图和欧拉函数
   - 欧拉图：包含欧拉回路的图，欧拉回路是能够通过图中所有的边一次且仅一次就通
过所有顶点的回路。
   - 欧拉函数：对自然数 n，从 0 到 n-1 中与 n 互素的数的个数就是欧拉函数 phi(n)。
   - 计算方法：对 n 个权值的集合，先分别计算每个权值对应的集合的欧拉函数，再将这
些集合合并，最后得到总的欧拉函数。
   - 应用：编码设计：Huffman 编码、决策算法、算法设计等。

2. 哈夫曼树
   - 定义：带权路径长度最小的二叉树。
   - 计算方法：用 n 个权重各创建一个平凡树，并赋该树根以权值，然后开始循环，循环内
容包括选择树根权值最小的两个树、创建一个新树、删去原来的两个树、添加新树以及判
断是否只剩一个树。
   - 应用：编码设计：Huffman 编码、决策算法、算法设计等。

3. 无向图
   - 定义：有序二元组，二元组由一个非空有限集——顶点集，和一个由顶点集的有限多重子集
——边集所构成。
   - 等价关系：如果非空集合 A 上的一个关系 R，同时满足自反性、对称性和传递性，就称 R
为集合 A 上的等价关系。
   - 等价类：集合 A 中所有与 x 等价的元素构成的集合。

4. 极限存在但不一定连续（因为连续必须在点上有定义，但是极限科研没有定义），连续一定存在极限。
```markdown
5. 欧拉图和欧拉函数
    - 欧拉图：包含欧拉回路的图，欧拉回路是能够通过图中所有的边一次且仅一次就通
过所有顶点的回路。
    - 欧拉函数：对自然数 n，从 0 到 n-1 中与 n 互素的数的个数就是欧拉函数 phi(n)。
    - 计算方法：对 n 个权值的集合，先分别计算每个权值对应的集合的欧拉函数，再将这
些集合合并，最后得到总的欧拉函数。
    - 应用：编码设计：Huffman 编码、决策算法、算法设计等。

6. 哈夫曼树
    - 定义：带权路径长度最小的二叉树。
    - 计算方法：用 n 个权重各创建一个平凡树，并赋该树根以权值，然后开始循环，循环内
容包括选择树根权值最小的两个树、创建一个新树、删去原来的两个树、添加新树以及判
断是否只剩一个树。
    - 应用：编码设计：Huffman 编码、决策算法、算法设计等。

7. 无向图
    - 定义：有序二元组，二元组由一个非空有限集——顶点集，和一个由顶点集的有限多重子集
——边集所构成。
    - 等价关系：如果非空集合 A 上的一个关系 R，同时满足自反性、对称性和传递性，就称 R
为集合 A 上的等价关系。
    - 等价类：集合 A 中所有与 x 等价的元素构成的集合。

8. 极限存在但不一定连续（因为连续必须在点上有定义，但是极限科研没有定义），连续一定存在极限。
```markdown
```

以下是提取的关键知识点：

1. **极限存在的三个条件：**
   - 在该点有定义；
   - 极限存在且等于函数值。

2. **间断点类型：**
   - 第一类间断点（a.跳跃间断点：左右极限存在且相等；b.可去间断点：在该点无定义）；
   - 第二类间断点（无穷间断点：左右极限至少有一个不存在）。

3. **如何寻找间断点：** 没有定义的点，或分段函数的分界点。

4. **介值定理：** 闭区间[a,b]上连续，一定存在一点 x 属于该区间使得 f(x)=c(其中 c 介于[f(a),f(b)]跟的存在定理即零点定理（f(x)在区间[a,b]上连续，且 f(a)·f(b)<0，则[a,b]必然存在一点 c 使得 f(c)=0）。